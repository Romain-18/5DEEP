{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e18e31b",
   "metadata": {},
   "source": [
    "# 5DEEP - Projet final : Classification des chants d'oiseaux\n",
    "\n",
    "Pour rappel:\n",
    "\n",
    "Il s'agit d'un problème de classification de chants d'oiseaux avec 5 classes, une pour chacune des espèces suivantes : \n",
    "\n",
    "- Bewick's Wren\n",
    "- Northern Cardinal\n",
    "- American Robin\n",
    "- Song Sparrow\n",
    "- Northern Mockingbird\n",
    "\n",
    "Pour répondre à cette problématique, nous utiliserons des réseaux de neuronnes que nous préparerons et entraînerons grâce à Keras et Librosa dans ce notebook Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0dd79",
   "metadata": {},
   "source": [
    "## Etape 1: Analyse exploratoire et comprehension des données\n",
    "\n",
    "Nous allons tout d'abord commencer par comprendre les différentes données mises à disposition, mais aussi comprendre l'interpretation de ces fichiers audio et leur traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df524035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bird_df = pd.read_csv(\"data/bird_songs_metadata.csv\")\n",
    "\n",
    "bird_df.head(10)\n",
    "\n",
    "bird_df.info()\n",
    "bird_df.isnull().sum()\n",
    "\n",
    "print(\"Nombre d'observations:\", len(bird_df))\n",
    "\n",
    "# On retire 'subspecies' car trop corrélée avec 'species' et pas de sens pour notre classification\n",
    "# 'recordist', 'license', 'remarks', 'source_url' n'apporte pas de sens pour notre classificiation\n",
    "\n",
    "# On conserve le 'filename' pour retrouver l'enregistrement associé\n",
    "\n",
    "\n",
    "# est-ce qu'on garde 'sound_type' ?? On filtre ceux qui ne sont pas 'song'\n",
    "\n",
    "# Notre variable cilble est 'species'\n",
    "\n",
    "bird_df_song_only = bird_df[bird_df['sound_type'].str.contains(\"song\", case=False, na=False)]\n",
    "\n",
    "cols = [\"id\", \"genus\", \"species\", \"name\", \"country\", \"location\", \n",
    "        \"latitude\", \"longitude\", \"altitude\", \"time\", \"date\", \"filename\", 'sound_type']\n",
    "bird_df_useful = bird_df_song_only[cols]\n",
    "\n",
    "bird_df_useful.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f76794",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distribution & corrélations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bird_df_useful['species'].value_counts().plot(kind='bar', figsize=(8,4))\n",
    "plt.title(\"Nombre d'échantillons par espèce\")\n",
    "plt.xlabel(\"Espèce\")\n",
    "plt.ylabel(\"Nombre d'enregistrements\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8557fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test librosa\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "sample_file = bird_df_useful['filename'].iloc[0]\n",
    "path = f\"data/wavfiles/{sample_file}\"\n",
    "y, sr = librosa.load(path, sr=22050, mono=True)\n",
    "\n",
    "# forme du signal\n",
    "plt.figure(figsize=(10,3))\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.title(f\"Waveform - {sample_file}\")\n",
    "plt.show()\n",
    "\n",
    "# mel spectrogram\n",
    "def extract_mel_spectrogram(file_path, sr=22050, n_mels=128, n_fft=2048, hop_length=512):\n",
    "    y, sr = librosa.load(file_path, sr=sr, mono=True)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
    "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    return log_mel.T # shape (time, n_mels)\n",
    "\n",
    "# mfcc \n",
    "def extract_mfcc(file_path, sr=22050, n_mfcc=40, n_fft=2048, hop_length=512):\n",
    "    y, sr = librosa.load(file_path, sr=sr, mono=True)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    return mfcc.T  # shape (time, n_mfcc)\n",
    "\n",
    "\n",
    "# test de la fonction mel spectrogram sur le sample\n",
    "mel_spec = extract_mel_spectrogram(f\"data/wavfiles/{sample_file}\")\n",
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(mel_spec.T, sr=sr, hop_length=512,\n",
    "                            x_axis=\"time\", y_axis=\"mel\")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Mel Specrtrogram\")\n",
    "plt.show()\n",
    "\n",
    "# test de la fonction mfcc sur le sample\n",
    "mfcc_feat = extract_mfcc(f\"data/wavfiles/{sample_file}\")\n",
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(mfcc_feat.T, sr=sr, hop_length=512,\n",
    "                            x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.title(\"MFCC\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bee134",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoding et pré-traitement des données audio\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# reucp la durée des enregistrements\n",
    "durations = []\n",
    "for f in bird_df_useful['filename']:\n",
    "    y, sr = librosa.load(f\"data/wavfiles/{f}\", sr=None)\n",
    "    durations.append(librosa.get_duration(y=y, sr=sr))\n",
    "bird_df_useful['duration'] = durations\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
