{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e18e31b",
   "metadata": {},
   "source": [
    "# 5DEEP - Projet final : Classification des chants d'oiseaux\n",
    "\n",
    "Pour rappel:\n",
    "\n",
    "Il s'agit d'un problème de classification de chants d'oiseaux avec 5 classes, une pour chacune des espèces suivantes : \n",
    "\n",
    "- Bewick's Wren\n",
    "- Northern Cardinal\n",
    "- American Robin\n",
    "- Song Sparrow\n",
    "- Northern Mockingbird\n",
    "\n",
    "Pour répondre à cette problématique, nous utiliserons des réseaux de neuronnes que nous préparerons et entraînerons grâce à Keras et Librosa dans ce notebook Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0dd79",
   "metadata": {},
   "source": [
    "## Etape 1: Analyse exploratoire et comprehension des données\n",
    "\n",
    "Nous allons tout d'abord commencer par comprendre les différentes données mises à disposition, mais aussi comprendre l'interpretation de ces fichiers audio et leur traitement.\n",
    "\n",
    "Quand nous récupérons des fichiers audio numérisés avec Librosa, nous avons :\n",
    "- La fréquence: grave, aigue, etc (Hz)\n",
    "- L'amplitude: Intensité/puissance du signal sonore (db)\n",
    "- Nb de canaux: nb de flux différents (mono / stéreo , +)\n",
    "- Fréquence d'échantillonage: la qualité audio (Hz ou kHz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df524035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bird_df = pd.read_csv(\"data/bird_songs_metadata.csv\")\n",
    "\n",
    "bird_df.head(10)\n",
    "\n",
    "bird_df.info()\n",
    "bird_df.isnull().sum()\n",
    "\n",
    "print(\"Nombre d'observations:\", len(bird_df))\n",
    "\n",
    "# On retire 'subspecies' car trop corrélée avec 'species' et pas de sens pour notre classification\n",
    "# 'recordist', 'license', 'remarks', 'source_url' n'apporte pas de sens pour notre classificiation\n",
    "\n",
    "# On conserve le 'filename' pour retrouver l'enregistrement associé\n",
    "\n",
    "# on retire 'species' car trop corrélée avec 'name' (même info mais scientifique vs commun)\n",
    "\n",
    "# 'sound_type' -> On filtre ceux qui ne sont pas 'song'\n",
    "\n",
    "# Notre variable cilble est 'species'\n",
    "\n",
    "bird_df_song_only = bird_df[bird_df['sound_type'].str.contains(\"song\", case=False, na=False)]\n",
    "\n",
    "cols = [\"id\", \"genus\", \"name\", \"country\", \"location\", \n",
    "        \"latitude\", \"longitude\", \"altitude\", \"time\", \"date\", \"filename\", 'sound_type']\n",
    "bird_df_useful = bird_df_song_only[cols]\n",
    "\n",
    "# on vire les observations qui ne n'ont pas de fichier audio\n",
    "bird_df_useful = bird_df_useful.dropna(subset=['filename'])\n",
    "\n",
    "bird_df_useful.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f76794",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distribution & corrélations (6eme point)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bird_df_useful['name'].value_counts().plot(kind='bar', figsize=(8,4))\n",
    "plt.title(\"Nombre d'échantillons par espèce\")\n",
    "plt.xlabel(\"Espèce\")\n",
    "plt.ylabel(\"Nombre d'enregistrements\")\n",
    "plt.show()\n",
    "\n",
    "actual_species = bird_df_useful['name'].unique()\n",
    "print(\"Espèces trouvées :\", actual_species)\n",
    "\n",
    "class_counts = bird_df_useful['name'].value_counts()\n",
    "print(\"Distribution des classes espèce:\")\n",
    "print(class_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8557fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test librosa\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "sample_file = bird_df_useful['filename'].iloc[0]\n",
    "path = f\"data/wavfiles/{sample_file}\"\n",
    "y, sr = librosa.load(path, sr=22050, mono=True)\n",
    "\n",
    "# forme du signal\n",
    "plt.figure(figsize=(10,3))\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.title(f\"Waveform - {sample_file}\")\n",
    "plt.show()\n",
    "\n",
    "# mel spectrogram\n",
    "def extract_mel_spectrogram(file_path, sr=22050, n_mels=128, n_fft=2048, hop_length=512):\n",
    "    y, sr = librosa.load(file_path, sr=sr, mono=True)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
    "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    return log_mel.T # shape (time, n_mels)\n",
    "\n",
    "# mfcc \n",
    "def extract_mfcc(file_path, sr=22050, n_mfcc=40, n_fft=2048, hop_length=512):\n",
    "    y, sr = librosa.load(file_path, sr=sr, mono=True)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    return mfcc.T  # shape (time, n_mfcc)\n",
    "\n",
    "\n",
    "# test de la fonction mel spectrogram sur le sample\n",
    "mel_spec = extract_mel_spectrogram(f\"data/wavfiles/{sample_file}\")\n",
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(mel_spec.T, sr=sr, hop_length=512,\n",
    "                            x_axis=\"time\", y_axis=\"mel\")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Mel Specrtrogram\")\n",
    "plt.show()\n",
    "\n",
    "# test de la fonction mfcc sur le sample\n",
    "mfcc_feat = extract_mfcc(f\"data/wavfiles/{sample_file}\")\n",
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(mfcc_feat.T, sr=sr, hop_length=512,\n",
    "                            x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.title(\"MFCC\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def analyze_audio_properties(df, sample_size=50):\n",
    "    \"\"\"Analyse les propriétés audio sur un échantillon\"\"\"\n",
    "    print(f\"\\n=== ANALYSE DES PROPRIÉTÉS AUDIO (échantillon de {sample_size}) ===\")\n",
    "    sample_df = df.sample(n=min(sample_size, len(df)), random_state=42)\n",
    "    \n",
    "    properties = []\n",
    "    for idx, row in sample_df.iterrows():\n",
    "        try:\n",
    "            y, sr = librosa.load(f\"data/wavfiles/{row['filename']}\", sr=None)\n",
    "            import soundfile as sf\n",
    "            try:\n",
    "                info = sf.info(f\"data/wavfiles/{row['filename']}\")\n",
    "                channels = info.channels\n",
    "            except:\n",
    "                channels = 1 if len(y.shape) == 1 else y.shape[0]\n",
    "            \n",
    "            properties.append({\n",
    "                'filename': row['filename'],\n",
    "                'species': row['name'],\n",
    "                'sample_rate': sr,\n",
    "                'channels': channels,\n",
    "                'duration': librosa.get_duration(y=y, sr=sr),\n",
    "                'samples': len(y)\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec {row['filename']}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(properties)\n",
    "audio_props = analyze_audio_properties(bird_df_useful, sample_size=100)\n",
    "print(audio_props.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1c1f9e",
   "metadata": {},
   "source": [
    "## Encoding & Sépération des différents datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0412d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "labels = bird_df_useful['name'].values\n",
    "encoder = LabelEncoder()\n",
    "y_int = encoder.fit_transform(labels)\n",
    "y = to_categorical(y_int)\n",
    "print(\"content de y :\", y[10:])\n",
    "print(\"Shape de y :\", y.shape)\n",
    "\n",
    "# on recup pour le moment juste les filenames, on constuira notre set de features plus tard\n",
    "# grace à librosa\n",
    "X = bird_df_useful['filename'].values\n",
    "\n",
    "# 70% train, 15% validation, 15% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "print(\"Train :\", len(X_train), \"Validation :\", len(X_val), \"Test :\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6fa90",
   "metadata": {},
   "source": [
    "## Encoding et pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bee134",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pré-traitement des données audio\n",
    "\n",
    "bird_df_useful_w_duration = bird_df_useful.copy()\n",
    "\n",
    "# reucp la durée des enregistrements\n",
    "durations = []\n",
    "for f in bird_df_useful['filename']:\n",
    "    y, sr = librosa.load(f\"data/wavfiles/{f}\", sr=None)\n",
    "    durations.append(librosa.get_duration(y=y, sr=sr))\n",
    "bird_df_useful_w_duration['duration'] = durations\n",
    "\n",
    "\n",
    "def prepare_dataset(file_list, base_path=\"data/wavfiles/\"):\n",
    "    features = []\n",
    "    for f in file_list:\n",
    "        path = base_path + f\n",
    "        mel_spec = extract_mel_spectrogram(path)\n",
    "        features.append(mel_spec)\n",
    "    return features\n",
    "\n",
    "# Exemple pour le train\n",
    "X_train_features = prepare_dataset(X_train)\n",
    "\n",
    "\n",
    "print(\"Exemple de feature shape:\", X_train_features[0].shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
